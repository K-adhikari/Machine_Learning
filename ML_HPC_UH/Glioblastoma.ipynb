{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7badc45c",
   "metadata": {},
   "source": [
    "Use the Machine Learning algorithms: Logistic Regression,\n",
    "KNN, K-means, Decision Tree, and Random Forest, with\n",
    "parameters optimization to classify Glioblastomas using the\n",
    "database Data_Glioblastoma5Patients_SC.csv and evaluate\n",
    "the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20517f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb82148",
   "metadata": {},
   "source": [
    "Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a3b472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430, 5949)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = pd.read_csv(\"./Data_Glioblastoma5Patients_SC.csv\")\n",
    "Data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e75377",
   "metadata": {},
   "source": [
    "It seems we have 430 rows and 5949 columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4a6498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AAK1</th>\n",
       "      <th>AAMP</th>\n",
       "      <th>AARS</th>\n",
       "      <th>AARSD1</th>\n",
       "      <th>AASDH</th>\n",
       "      <th>AASDHPPT</th>\n",
       "      <th>AASS</th>\n",
       "      <th>AATF</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSWIM6</th>\n",
       "      <th>ZSWIM7</th>\n",
       "      <th>ZUFSP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>-3.985616</td>\n",
       "      <td>2.651558</td>\n",
       "      <td>2.170748</td>\n",
       "      <td>-2.550822</td>\n",
       "      <td>4.807330</td>\n",
       "      <td>3.961170</td>\n",
       "      <td>-0.192665</td>\n",
       "      <td>3.614482</td>\n",
       "      <td>...</td>\n",
       "      <td>2.909466</td>\n",
       "      <td>-3.118284</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>-1.920271</td>\n",
       "      <td>3.007439</td>\n",
       "      <td>-2.509017</td>\n",
       "      <td>-2.149696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>-3.158708</td>\n",
       "      <td>2.358992</td>\n",
       "      <td>-6.041792</td>\n",
       "      <td>-0.056092</td>\n",
       "      <td>3.606735</td>\n",
       "      <td>-2.632250</td>\n",
       "      <td>2.249388</td>\n",
       "      <td>6.857517</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.821098</td>\n",
       "      <td>-3.118284</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>-3.068620</td>\n",
       "      <td>2.539560</td>\n",
       "      <td>2.164481</td>\n",
       "      <td>-2.149696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>1.733125</td>\n",
       "      <td>-5.820241</td>\n",
       "      <td>-6.041792</td>\n",
       "      <td>-0.576957</td>\n",
       "      <td>-2.473517</td>\n",
       "      <td>-4.354127</td>\n",
       "      <td>0.063178</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.821098</td>\n",
       "      <td>5.521892</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>0.174665</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>0.734268</td>\n",
       "      <td>-2.149696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>-1.665669</td>\n",
       "      <td>3.514271</td>\n",
       "      <td>-6.041792</td>\n",
       "      <td>-3.699171</td>\n",
       "      <td>4.509461</td>\n",
       "      <td>-4.354127</td>\n",
       "      <td>2.985972</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>4.952176</td>\n",
       "      <td>-0.854351</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>-3.068620</td>\n",
       "      <td>-1.884744</td>\n",
       "      <td>-2.509017</td>\n",
       "      <td>-2.149696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>3.742495</td>\n",
       "      <td>-2.166992</td>\n",
       "      <td>-5.820241</td>\n",
       "      <td>2.094729</td>\n",
       "      <td>4.021873</td>\n",
       "      <td>5.535007</td>\n",
       "      <td>4.019633</td>\n",
       "      <td>2.560370</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.821098</td>\n",
       "      <td>4.328808</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>7.021985</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>4.590946</td>\n",
       "      <td>-0.128456</td>\n",
       "      <td>-2.509017</td>\n",
       "      <td>-2.149696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.98770</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>4.691156</td>\n",
       "      <td>-4.006471</td>\n",
       "      <td>-3.449348</td>\n",
       "      <td>4.309767</td>\n",
       "      <td>4.002960</td>\n",
       "      <td>5.123457</td>\n",
       "      <td>0.341512</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>4.176419</td>\n",
       "      <td>-2.370500</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>-3.068620</td>\n",
       "      <td>-3.421540</td>\n",
       "      <td>-2.509017</td>\n",
       "      <td>-2.149696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>2.656469</td>\n",
       "      <td>2.207608</td>\n",
       "      <td>-6.041792</td>\n",
       "      <td>4.235937</td>\n",
       "      <td>0.716257</td>\n",
       "      <td>-1.164354</td>\n",
       "      <td>2.630053</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.821098</td>\n",
       "      <td>0.071490</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>5.651368</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>3.617386</td>\n",
       "      <td>1.384471</td>\n",
       "      <td>-2.509017</td>\n",
       "      <td>-2.149696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>-1.914759</td>\n",
       "      <td>2.417820</td>\n",
       "      <td>3.162904</td>\n",
       "      <td>-3.699171</td>\n",
       "      <td>-2.473517</td>\n",
       "      <td>-4.354127</td>\n",
       "      <td>1.970206</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.821098</td>\n",
       "      <td>3.615788</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>1.829214</td>\n",
       "      <td>5.237998</td>\n",
       "      <td>-2.509017</td>\n",
       "      <td>6.779879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>0.483560</td>\n",
       "      <td>-5.820241</td>\n",
       "      <td>-6.041792</td>\n",
       "      <td>-3.699171</td>\n",
       "      <td>-2.473517</td>\n",
       "      <td>4.889074</td>\n",
       "      <td>-3.847544</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.821098</td>\n",
       "      <td>-3.118284</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>-3.068620</td>\n",
       "      <td>-0.775154</td>\n",
       "      <td>1.953289</td>\n",
       "      <td>-2.149696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>4.316243</td>\n",
       "      <td>1.828663</td>\n",
       "      <td>2.140173</td>\n",
       "      <td>-6.041792</td>\n",
       "      <td>3.721094</td>\n",
       "      <td>3.479903</td>\n",
       "      <td>-4.354127</td>\n",
       "      <td>-4.860593</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.821098</td>\n",
       "      <td>-0.860025</td>\n",
       "      <td>0.841462</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>5.157919</td>\n",
       "      <td>4.710859</td>\n",
       "      <td>5.078266</td>\n",
       "      <td>4.977025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 5949 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A2M      AAAS      AAK1      AAMP      AARS    AARSD1     AASDH  \\\n",
       "0 -3.80147 -3.889900 -3.985616  2.651558  2.170748 -2.550822  4.807330   \n",
       "1 -3.80147 -3.889900 -3.158708  2.358992 -6.041792 -0.056092  3.606735   \n",
       "2 -3.80147 -3.889900  1.733125 -5.820241 -6.041792 -0.576957 -2.473517   \n",
       "3 -3.80147 -3.889900 -1.665669  3.514271 -6.041792 -3.699171  4.509461   \n",
       "4 -3.80147  3.742495 -2.166992 -5.820241  2.094729  4.021873  5.535007   \n",
       "5 -1.98770 -3.889900  4.691156 -4.006471 -3.449348  4.309767  4.002960   \n",
       "6 -3.80147 -3.889900  2.656469  2.207608 -6.041792  4.235937  0.716257   \n",
       "7 -3.80147 -3.889900 -1.914759  2.417820  3.162904 -3.699171 -2.473517   \n",
       "8 -3.80147 -3.889900  0.483560 -5.820241 -6.041792 -3.699171 -2.473517   \n",
       "9 -3.80147  4.316243  1.828663  2.140173 -6.041792  3.721094  3.479903   \n",
       "\n",
       "   AASDHPPT      AASS      AATF  ...    ZSWIM6    ZSWIM7     ZUFSP      ZW10  \\\n",
       "0  3.961170 -0.192665  3.614482  ...  2.909466 -3.118284 -1.538324 -1.550699   \n",
       "1 -2.632250  2.249388  6.857517  ... -1.821098 -3.118284 -1.538324 -1.550699   \n",
       "2 -4.354127  0.063178 -2.570976  ... -1.821098  5.521892 -1.538324 -1.550699   \n",
       "3 -4.354127  2.985972 -2.570976  ...  4.952176 -0.854351 -1.538324 -1.550699   \n",
       "4  4.019633  2.560370 -2.570976  ... -1.821098  4.328808 -1.538324  7.021985   \n",
       "5  5.123457  0.341512 -2.570976  ...  4.176419 -2.370500 -1.538324 -1.550699   \n",
       "6 -1.164354  2.630053 -2.570976  ... -1.821098  0.071490 -1.538324  5.651368   \n",
       "7 -4.354127  1.970206 -2.570976  ... -1.821098  3.615788 -1.538324 -1.550699   \n",
       "8  4.889074 -3.847544 -2.570976  ... -1.821098 -3.118284 -1.538324 -1.550699   \n",
       "9 -4.354127 -4.860593 -2.570976  ... -1.821098 -0.860025  0.841462 -1.550699   \n",
       "\n",
       "     ZWILCH      ZXDC    ZYG11B       ZYX      ZZZ3  Classes  \n",
       "0 -1.558581 -1.920271  3.007439 -2.509017 -2.149696        1  \n",
       "1 -1.558581 -3.068620  2.539560  2.164481 -2.149696        1  \n",
       "2 -1.558581  0.174665 -0.165409  0.734268 -2.149696        1  \n",
       "3 -1.558581 -3.068620 -1.884744 -2.509017 -2.149696        1  \n",
       "4 -1.558581  4.590946 -0.128456 -2.509017 -2.149696        1  \n",
       "5 -1.558581 -3.068620 -3.421540 -2.509017 -2.149696        1  \n",
       "6 -1.558581  3.617386  1.384471 -2.509017 -2.149696        1  \n",
       "7 -1.558581  1.829214  5.237998 -2.509017  6.779879        1  \n",
       "8 -1.558581 -3.068620 -0.775154  1.953289 -2.149696        1  \n",
       "9 -1.558581  5.157919  4.710859  5.078266  4.977025        1  \n",
       "\n",
       "[10 rows x 5949 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b025edb",
   "metadata": {},
   "source": [
    "'Classes' column in the dataset contains the labels. So, I am going to check how many unique labels are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8822ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Classes'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821482df",
   "metadata": {},
   "source": [
    "Now, I am going to define the features and labels from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75160f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AAK1</th>\n",
       "      <th>AAMP</th>\n",
       "      <th>AARS</th>\n",
       "      <th>AARSD1</th>\n",
       "      <th>AASDH</th>\n",
       "      <th>AASDHPPT</th>\n",
       "      <th>AASS</th>\n",
       "      <th>AATF</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSCAN30</th>\n",
       "      <th>ZSWIM6</th>\n",
       "      <th>ZSWIM7</th>\n",
       "      <th>ZUFSP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>-3.985616</td>\n",
       "      <td>2.651558</td>\n",
       "      <td>2.170748</td>\n",
       "      <td>-2.550822</td>\n",
       "      <td>4.807330</td>\n",
       "      <td>3.961170</td>\n",
       "      <td>-0.192665</td>\n",
       "      <td>3.614482</td>\n",
       "      <td>...</td>\n",
       "      <td>6.262256</td>\n",
       "      <td>2.909466</td>\n",
       "      <td>-3.118284</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>-1.920271</td>\n",
       "      <td>3.007439</td>\n",
       "      <td>-2.509017</td>\n",
       "      <td>-2.149696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>-3.158708</td>\n",
       "      <td>2.358992</td>\n",
       "      <td>-6.041792</td>\n",
       "      <td>-0.056092</td>\n",
       "      <td>3.606735</td>\n",
       "      <td>-2.632250</td>\n",
       "      <td>2.249388</td>\n",
       "      <td>6.857517</td>\n",
       "      <td>...</td>\n",
       "      <td>2.912340</td>\n",
       "      <td>-1.821098</td>\n",
       "      <td>-3.118284</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>-3.068620</td>\n",
       "      <td>2.539560</td>\n",
       "      <td>2.164481</td>\n",
       "      <td>-2.149696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>1.733125</td>\n",
       "      <td>-5.820241</td>\n",
       "      <td>-6.041792</td>\n",
       "      <td>-0.576957</td>\n",
       "      <td>-2.473517</td>\n",
       "      <td>-4.354127</td>\n",
       "      <td>0.063178</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.593571</td>\n",
       "      <td>-1.821098</td>\n",
       "      <td>5.521892</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>0.174665</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>0.734268</td>\n",
       "      <td>-2.149696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>-3.889900</td>\n",
       "      <td>-1.665669</td>\n",
       "      <td>3.514271</td>\n",
       "      <td>-6.041792</td>\n",
       "      <td>-3.699171</td>\n",
       "      <td>4.509461</td>\n",
       "      <td>-4.354127</td>\n",
       "      <td>2.985972</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>4.453041</td>\n",
       "      <td>4.952176</td>\n",
       "      <td>-0.854351</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>-1.550699</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>-3.068620</td>\n",
       "      <td>-1.884744</td>\n",
       "      <td>-2.509017</td>\n",
       "      <td>-2.149696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.80147</td>\n",
       "      <td>3.742495</td>\n",
       "      <td>-2.166992</td>\n",
       "      <td>-5.820241</td>\n",
       "      <td>2.094729</td>\n",
       "      <td>4.021873</td>\n",
       "      <td>5.535007</td>\n",
       "      <td>4.019633</td>\n",
       "      <td>2.560370</td>\n",
       "      <td>-2.570976</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.593571</td>\n",
       "      <td>-1.821098</td>\n",
       "      <td>4.328808</td>\n",
       "      <td>-1.538324</td>\n",
       "      <td>7.021985</td>\n",
       "      <td>-1.558581</td>\n",
       "      <td>4.590946</td>\n",
       "      <td>-0.128456</td>\n",
       "      <td>-2.509017</td>\n",
       "      <td>-2.149696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5948 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A2M      AAAS      AAK1      AAMP      AARS    AARSD1     AASDH  \\\n",
       "0 -3.80147 -3.889900 -3.985616  2.651558  2.170748 -2.550822  4.807330   \n",
       "1 -3.80147 -3.889900 -3.158708  2.358992 -6.041792 -0.056092  3.606735   \n",
       "2 -3.80147 -3.889900  1.733125 -5.820241 -6.041792 -0.576957 -2.473517   \n",
       "3 -3.80147 -3.889900 -1.665669  3.514271 -6.041792 -3.699171  4.509461   \n",
       "4 -3.80147  3.742495 -2.166992 -5.820241  2.094729  4.021873  5.535007   \n",
       "\n",
       "   AASDHPPT      AASS      AATF  ...   ZSCAN30    ZSWIM6    ZSWIM7     ZUFSP  \\\n",
       "0  3.961170 -0.192665  3.614482  ...  6.262256  2.909466 -3.118284 -1.538324   \n",
       "1 -2.632250  2.249388  6.857517  ...  2.912340 -1.821098 -3.118284 -1.538324   \n",
       "2 -4.354127  0.063178 -2.570976  ... -2.593571 -1.821098  5.521892 -1.538324   \n",
       "3 -4.354127  2.985972 -2.570976  ...  4.453041  4.952176 -0.854351 -1.538324   \n",
       "4  4.019633  2.560370 -2.570976  ... -2.593571 -1.821098  4.328808 -1.538324   \n",
       "\n",
       "       ZW10    ZWILCH      ZXDC    ZYG11B       ZYX      ZZZ3  \n",
       "0 -1.550699 -1.558581 -1.920271  3.007439 -2.509017 -2.149696  \n",
       "1 -1.550699 -1.558581 -3.068620  2.539560  2.164481 -2.149696  \n",
       "2 -1.550699 -1.558581  0.174665 -0.165409  0.734268 -2.149696  \n",
       "3 -1.550699 -1.558581 -3.068620 -1.884744 -2.509017 -2.149696  \n",
       "4  7.021985 -1.558581  4.590946 -0.128456 -2.509017 -2.149696  \n",
       "\n",
       "[5 rows x 5948 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Data.drop(columns = \"Classes\")\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9f0de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Classes, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = Data[\"Classes\"]\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14c302",
   "metadata": {},
   "source": [
    "Now, I will split the dataset into training and test dataset where I will be using 80% of the dataset for training and remianing 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8481b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6830d4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344, 5948) (86, 5948) (344,) (86,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fecd182",
   "metadata": {},
   "source": [
    "Next, I want to use different machine learning algorithms namely: Logistic Regression, KNN, Decision Tree, and Random Forest to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be19bb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.982353 (0.019510)\n",
      "KNN: 0.634034 (0.070064)\n",
      "DT: 0.866134 (0.040134)\n",
      "RF: 0.965042 (0.028550)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree, model_selection\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('DT', tree.DecisionTreeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=0)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c056e",
   "metadata": {},
   "source": [
    "It seems like Linear Regression is the best fit for our data with an accuracy of 0.98. We can also check this by plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e884c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f721444",
   "metadata": {},
   "source": [
    "Plot confirms that logistic regression is the best model. Now, I want to make sure if LR best fits the test dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f22a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9767441860465116\n",
      "[[23  0  0  0  1]\n",
      " [ 0 23  0  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 1  0  0 13  0]\n",
      " [ 0  0  0  0 13]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ka422/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "# Now, I want to make predictions on the validation data set and print out accuracy score and confusion matrix\n",
    "predictions = LR.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ef577",
   "metadata": {},
   "source": [
    "The accuracy score for the test dataset using the LR is ~ 0.98, which is similar to that of training datset, suggesting the best model. This also get validated by the confusuin matrix, where we can see there are only two instances of misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384e7dd",
   "metadata": {},
   "source": [
    "Random Forest had an accuracy of 0.95 for training dataset. Now, we can check the accuracy of this model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592a998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9883720930232558\n",
      "[[24  0  0  0  0]\n",
      " [ 0 23  0  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 1  0  0 13  0]\n",
      " [ 0  0  0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "predictions = RF.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2dc41",
   "metadata": {},
   "source": [
    "The accuracy of RF for test set is 0.95, which is similar to the training dataset but lowe than that of LR. We can check if the accuracy of this model can be increased by iterating over classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18bb772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9534883720930233\n",
      "[[23  1  0  0  0]\n",
      " [ 0 23  0  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 0  0  0 13  1]\n",
      " [ 1  0  0  1 11]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "conf_te = confusion_matrix(y_test, clf.predict(X_test))\n",
    "\n",
    "import numpy as np\n",
    "def accuracy(conf):\n",
    "    total_correct = 0.\n",
    "    nb_classes = conf.shape[0]\n",
    "    for i in np.arange(0,nb_classes):\n",
    "        total_correct += conf[i][i]\n",
    "    acc = total_correct/sum(sum(conf))\n",
    "    return acc\n",
    "print(accuracy(conf_te),)\n",
    "print (conf_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a524c1",
   "metadata": {},
   "source": [
    "As we can see the performance of the model doesn't increase by iterating over the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b1dd4",
   "metadata": {},
   "source": [
    "Next, we can check how the Decision Tree performs on our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4edb7148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872093023255814\n",
      "[[23  0  0  0  1]\n",
      " [ 1 21  1  0  0]\n",
      " [ 0  1 11  0  0]\n",
      " [ 0  1  2 11  0]\n",
      " [ 0  1  1  2  9]]\n"
     ]
    }
   ],
   "source": [
    "DT=tree.DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)\n",
    "predictions = DT.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b99bf6",
   "metadata": {},
   "source": [
    "Decision tree performs similar for both training and test datasets. Now, we can try the KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4a69dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#KNN Classifier \n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "#Here, I am going to try KNN for diffrent k nearest neighbor from 1 to 20\n",
    "neighbors_setting = range(1,20)\n",
    "\n",
    "for n_neighbors in neighbors_setting:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train,y_train)\n",
    "    training_accuracy.append(knn.score(X_train, y_train))\n",
    "    test_accuracy.append(knn.score(X_test, y_test))\n",
    " \n",
    "plt.plot(neighbors_setting,training_accuracy, label='Accuracy of the training set')\n",
    "plt.plot(neighbors_setting,test_accuracy, label='Accuracy of the test set')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f46a6f",
   "metadata": {},
   "source": [
    "By looking at the plot, it doesn't look like the accuracy of training and test set match each other but they get closer to each other whennumber of neighbors are 8 and 17. But those test accuracy are lower than what we observed with LR and RF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1a774a",
   "metadata": {},
   "source": [
    "Next, we can look at KMeans algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2d745a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23255813953488372\n",
      "[[ 0  0  0  0  0  0]\n",
      " [21  1  2  0  0  0]\n",
      " [ 0  4 19  0  0  0]\n",
      " [ 1  0 11  0  0  0]\n",
      " [ 3  2  9  0  0  0]\n",
      " [ 0 10  3  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clf = KMeans(n_clusters=3, random_state=1)\n",
    "clf.fit(X_train,y_train)\n",
    "conf_te = confusion_matrix(y_test, clf.predict(X_test))\n",
    "def accuracy(conf):\n",
    "    total_correct = 0.\n",
    "    nb_classes = conf.shape[0]\n",
    "    for i in np.arange(0,nb_classes):\n",
    "        total_correct += conf[i][i]\n",
    "    acc = total_correct/sum(sum(conf))\n",
    "    return acc\n",
    "\n",
    "print(accuracy(conf_te),)\n",
    "print(conf_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed3ba1e",
   "metadata": {},
   "source": [
    "KMeans seems to do worse with our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b7b12",
   "metadata": {},
   "source": [
    "So, Logistic Regression seems to be the model that best fits our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5946fb23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
